{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework of Ch4. Image Classification by Convolutional Neural Network\n",
    "----\n",
    "This is the homework snippet of TU-ETP-AD1062 Machine Learning Fundamentals.\n",
    "\n",
    "For more information, please refer to:\n",
    "https://sites.google.com/view/tu-ad1062-mlfundamentals/\n",
    "\n",
    "> You do NOT have to build up from nothing, please try your best for the following parts:\n",
    "> - **Your task: HW4.2.1.**\n",
    "> - **Your task: HW4.3.1.**\n",
    "> - **Your task: HW4.3.2.**\n",
    "> - **Your task: HW4.3.3.**\n",
    "> - **Your task: HW4.4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.1. Import Packages\n",
    "----\n",
    "- Data pre-processing:\n",
    "    - `os`: Used for path join\n",
    "    - `sklearn.preprocessing.LabelEncoder`: Convert string-based labels into numeric labels\n",
    "    - `PIL.Image`: For image file read and manipulation\n",
    "    - `pandas`: Used for CSV reading and writing\n",
    "- Models construction:\n",
    "    - `models.*`, `layers.*`, and `optimizers.*`: For loading related components layers to constructing convolutional neural network\n",
    "    - `utils.to_categorical`: For converting numerical labels into categorical labels\n",
    "- Performance evaluation:\n",
    "    - `sklearn.metrics.zero_one_loss`: Used for accuracy evaluation\n",
    "    - `sklearn.model_selection.train_test_split`: Divide your data into training and validation set for once, then feed into classifier by yourself, observing the score and confusion matrix\n",
    "    - `mlfund.plot.PlotMetric`: plot confusion matrix (provided by this repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!pip install pandas\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Conv1D, Conv2D, MaxPooling2D, GlobalMaxPooling1D, GlobalAveragePooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mlfund.plot import PlotMetric\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.2. Data pre-processing\n",
    "----\n",
    "The code snippet is used to read image files, with corresponded labels provided in its parent directory, i.e.,\n",
    "- `buildings`\n",
    "- `forest`\n",
    "- `glacier` \n",
    "- `mountain`\n",
    "- `sea`\n",
    "- `street`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW4.2.1. Read Image Files\n",
    "----\n",
    "Prepare image files as `X_train`, which is an `numpy.ndarray` instance, and string-based label list `y_train_str`\n",
    "\n",
    "> **Your task: HW4.2.1.**\n",
    "> Try to adjust your `target_size` based on the training result below. You may have to adjust several times to have a better result. Remember that:\n",
    "> - The higher `target_size`: Means more details learned into convolution layer, which means you may requires corresponded  pooling layer to reduce effects caused by spatial variations. Also, more computation time is required.\n",
    "> - The lower `target_size`: Means less details reserved. It consumes less computation time, but some information which helps training and classification might be missed, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet helps you to read the image file. You don't have to modify the block shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "\n",
    "# Training set\n",
    "def prepare_training_set():\n",
    "    X_train = np.empty((0, target_size[0], target_size[1], 3), dtype='uint8')\n",
    "    y_train_str = []\n",
    "    sha1_train = []\n",
    "\n",
    "    for label in labels:\n",
    "        dir_path_current = os.path.join('data', 'hw4', 'train', label)\n",
    "        print('Processing %s ...' % dir_path_current)\n",
    "\n",
    "        filelist_img = os.listdir(dir_path_current)\n",
    "\n",
    "        # Images\n",
    "        X_label_set = np.array([np.array(Image.open(os.path.join(dir_path_current, filename_img)).resize( target_size )) for filename_img in filelist_img])\n",
    "        X_train = np.append(X_train, X_label_set, axis=0)\n",
    "\n",
    "        # Labels\n",
    "        y_train_str = y_train_str + ([label] * len(X_label_set))\n",
    "\n",
    "        # SHA1\n",
    "        sha1_train = sha1_train + [filename_img.split('.')[0] for filename_img in filelist_img ]\n",
    "\n",
    "    # Shuffle by SHA1\n",
    "    idx_sorted = np.argsort(sha1_train)\n",
    "\n",
    "    X_train = X_train[idx_sorted, :]\n",
    "    y_train_str = np.array(y_train_str)[idx_sorted]\n",
    "    sha1_train = np.array(sha1_train)[idx_sorted]\n",
    "    \n",
    "    return X_train, y_train_str, sha1_train\n",
    "\n",
    "\n",
    "# Testing test\n",
    "def prepare_testing_set():\n",
    "    X_test = np.empty((0, target_size[0], target_size[1], 3), dtype='uint8')\n",
    "    sha1_test = []\n",
    "\n",
    "    dir_path_current = os.path.join('data', 'hw4', 'test')\n",
    "    print('Processing %s ...' % dir_path_current)\n",
    "\n",
    "    filelist_img = os.listdir(dir_path_current)\n",
    "\n",
    "    # Images\n",
    "    X_test = np.array([np.array(Image.open(os.path.join(dir_path_current, filename_img)).resize( target_size )) for filename_img in filelist_img])\n",
    "\n",
    "    # SHA1\n",
    "    sha1_test = [filename_img.split('.')[0] for filename_img in filelist_img ]\n",
    "    \n",
    "    return X_test, sha1_test\n",
    "\n",
    "\n",
    "X_train, y_train_str, sha1_train = prepare_training_set()\n",
    "X_test, sha1_test = prepare_testing_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW4.2.2. Convert String Label to Numeric Labels\n",
    "----\n",
    "Use `LabelEncoder` to convert the string-based labels into `0`, `1`, `2`, ..., and `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train_str)\n",
    "\n",
    "y_train = label_encoder.transform(y_train_str)\n",
    "\n",
    "display( [ (idx, label) for idx, label in enumerate(label_encoder.classes_) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW4.2.3. Show the First 10 images for each Category\n",
    "----\n",
    "It provides an overview of the 6 classes dataset after image resized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "\n",
    "for label in np.unique(y_train):\n",
    "    plt.figure(figsize=(16, 2))\n",
    "    plt.suptitle(label_encoder.classes_[label])\n",
    "    \n",
    "    X_label_set = X_train[y_train == label]\n",
    "    for i in range(0, 10):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow(X_label_set[i,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.3. Construct your Classifier\n",
    "----\n",
    "> **Your task: HW4.3.1**  \n",
    "> Build your own Neural Network models by Keras framework, try to maximize the performance by adjust the model structures.\n",
    "> Some documents listed below might be useful:\n",
    "> - Convolutional layer: https://keras.io/layers/convolutional/\n",
    "> - Pooling layer: https://keras.io/layers/pooling/\n",
    "> - Dropout layer: https://keras.io/layers/core/#dropout\n",
    "> - Dense (Fully-connected) layer: https://keras.io/layers/core/#dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convNet(num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(100, kernel_size=(3,3), activation='relu', input_shape=(target_size[0], target_size[1], 3)))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Conv2D(50, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50,activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(6,activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet helps you to split the known, training data `X_train`, `y_train` into `X1`, `X2`, `y1`, `y2` for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2, y1, y2 = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "y1_categorical = to_categorical(y1)\n",
    "y2_categorical = to_categorical(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Your task: HW4.3.2**  \n",
    "> Adjust your `fit` process for training, including `batch_size` and `epochs` to meet your hardware conditions.\n",
    "> \n",
    "> For more details, see: https://keras.io/models/model/#fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = create_convNet(len(label_encoder.classes_))\n",
    "model.summary()\n",
    "\n",
    "batch_size=64\n",
    "epochs=10\n",
    "\n",
    "model.fit(X1, y1_categorical, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Your task: HW4.3.3**  \n",
    "> Check the zero-one-loss and confusion matrix to adjust the performance.\n",
    ">\n",
    "> **Notice:** In general, one should conduct cross-validation mentioned in Chapter 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_categorical_predict = model.predict(X2)\n",
    "y2_predict = np.argmax(y2_categorical_predict, axis=1)\n",
    "\n",
    "# Error rate\n",
    "err_01loss = zero_one_loss(y2, y2_predict)\n",
    "print('Error rate = %2.3f' % err_01loss)\n",
    "\n",
    "# Confusion matrix of prediction\n",
    "plot_conf_mat = PlotMetric(figsize=(6,6))\n",
    "plot_conf_mat.set_labels(label_encoder.classes_.tolist())\n",
    "plot_conf_mat.confusion_matrix(y2, y2_predict, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.4. Submit to Kaggle InClass\n",
    "----\n",
    "> **Your task: HW4.4.**\n",
    "> 1. Training with full data set `X_train` with the model created by `create_convNet`,\n",
    "> 2. Predict the **unknown** testing data `X_test` by the trained model, then\n",
    "> 3. Submit your result to Kaggle\n",
    "\n",
    "**Notice: You got 5 chances to submit your result every day.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and train\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "\n",
    "model = create_convNet(len(label_encoder.classes_))\n",
    "model.fit(X_train, y_train_categorical, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# Predict the testing data\n",
    "y_test_categorical_predict = model.predict(X_test)\n",
    "y_test_predict = np.argmax(y_test_categorical_predict, axis=1)\n",
    "y_test_predict_str = label_encoder.inverse_transform(y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you submit\n",
    "----\n",
    "Please join the homework 4 competition by **using the Email ended with \\@trendmicro.com as your Kaggle InClass team name**.\n",
    "\n",
    "Type your Email in the variable `my_trendmicro_email_which_is_also_my_team_name` to make sure you've already read this paragraph, then the following code snippet will help you to generate the csv file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_trendmicro_email_which_is_also_my_team_name = ''\n",
    "\n",
    "import re\n",
    "assert re.match(r\"[^@]+@trendmicro.com\", my_trendmicro_email_which_is_also_my_team_name), \"Please read the instruction above paragraph carefully\"\n",
    "\n",
    "target_path = 'data/hw04.result.csv'\n",
    "df_test_label = pd.DataFrame({'id': sha1_test, 'label': y_test_predict_str})\n",
    "df_test_label.to_csv(target_path, index=False)\n",
    "\n",
    "print('Congratulation! Please submit your result \\'%s\\' to https://www.kaggle.com/t/f462abb1fb02461eba8318493c482c7a' % target_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
