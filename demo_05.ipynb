{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of Ch5. Sequential Learning\n",
    "----\n",
    "This is the sample code of TU-ETP-AD1062 Machine Learning Fundamentals.\n",
    "\n",
    "For more information, please refer to:\n",
    "https://sites.google.com/view/tu-ad1062-mlfundamentals/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "----\n",
    "- `keras`:\n",
    "    - `preprocessing.*`: text cleanup, text pre-processing, and text sequences tokenization before import into models\n",
    "    - `models.*`, `embeddings.*`, `layers.*`, and `optimizers.*`: For loading related components layers to constructing recurrent neural network (including both LSTM, GRU or the simplest version RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import codecs\n",
    "\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mlfund.plot import PlotMetric\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "----\n",
    "The **SMS Spam Collection Data Set** is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,572 messages, tagged acording being ham (legitimate) or spam.\n",
    "\n",
    "For more information, see: https://archive.ics.uci.edu/ml/datasets/sms+spam+collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thats the way u feel. Thats the way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>I‘m going to try for 2 months ha ha only joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So ü pay first lar... Then when is da stock co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>ham</td>\n",
       "      <td>Armand says get your ass over to epsilon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>ham</td>\n",
       "      <td>U still havent got urself a jacket ah?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm taking derek &amp;amp; taylor to walmart, if I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi its in durban are you still on this number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ic. There are a lotta childporn cars then.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>ham</td>\n",
       "      <td>No, I was trying it all weekend ;V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>ham</td>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, what time you think you can get here?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wen did you get so spiritual and deep. That's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well keep in mind I've only got enough gas for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you aren't here in the next  &amp;lt;#&amp;gt;  hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>ham</td>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Huh y lei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            content\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6      ham  Even my brother is not like to speak with me. ...\n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8     spam  WINNER!! As a valued network customer you have...\n",
       "9     spam  Had your mobile 11 months or more? U R entitle...\n",
       "10     ham  I'm gonna be home soon and i don't want to tal...\n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12    spam  URGENT! You have won a 1 week FREE membership ...\n",
       "13     ham  I've been searching for the right words to tha...\n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "16     ham                         Oh k...i'm watching here:)\n",
       "17     ham  Eh u remember how 2 spell his name... Yes i di...\n",
       "18     ham  Fine if thats the way u feel. Thats the way ...\n",
       "19    spam  England v Macedonia - dont miss the goals/team...\n",
       "20     ham          Is that seriously how you spell his name?\n",
       "21     ham    I‘m going to try for 2 months ha ha only joking\n",
       "22     ham  So ü pay first lar... Then when is da stock co...\n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...\n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...\n",
       "25     ham  Just forced myself to eat a slice. I'm really ...\n",
       "26     ham                     Lol your always so convincing.\n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...\n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...\n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...\n",
       "...    ...                                                ...\n",
       "5542   ham           Armand says get your ass over to epsilon\n",
       "5543   ham             U still havent got urself a jacket ah?\n",
       "5544   ham  I'm taking derek &amp; taylor to walmart, if I...\n",
       "5545   ham      Hi its in durban are you still on this number\n",
       "5546   ham         Ic. There are a lotta childporn cars then.\n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5548   ham                 No, I was trying it all weekend ;V\n",
       "5549   ham  You know, wot people wear. T shirts, jumpers, ...\n",
       "5550   ham        Cool, what time you think you can get here?\n",
       "5551   ham  Wen did you get so spiritual and deep. That's ...\n",
       "5552   ham  Have a safe trip to Nigeria. Wish you happines...\n",
       "5553   ham                        Hahaha..use your brain dear\n",
       "5554   ham  Well keep in mind I've only got enough gas for...\n",
       "5555   ham  Yeh. Indians was nice. Tho it did kane me off ...\n",
       "5556   ham  Yes i have. So that's why u texted. Pshew...mi...\n",
       "5557   ham  No. I meant the calculation is the same. That ...\n",
       "5558   ham                             Sorry, I'll call later\n",
       "5559   ham  if you aren't here in the next  &lt;#&gt;  hou...\n",
       "5560   ham                  Anything lor. Juz both of us lor.\n",
       "5561   ham  Get me out of this dump heap. My mom decided t...\n",
       "5562   ham  Ok lor... Sony ericsson salesman... I ask shuh...\n",
       "5563   ham                                Ard 6 like dat lor.\n",
       "5564   ham  Why don't you wait 'til at least wednesday to ...\n",
       "5565   ham                                       Huh y lei...\n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = os.path.join('data', 'demo5')\n",
    "dataset_path = os.path.join('data', 'demo5', 'SMSSpamCollection')\n",
    "\n",
    "def download_dataset():\n",
    "    r = requests.get('https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip')\n",
    "    if r.status_code == 200:\n",
    "        f_zip = ZipFile(BytesIO(r.content))\n",
    "\n",
    "        dataset_raw_content = f_zip.read('SMSSpamCollection')\n",
    "        with open(dataset_path, 'wb') as f_dataset:\n",
    "            f_dataset.write(b'label\\tcontent\\n')\n",
    "            f_dataset.write(dataset_raw_content)\n",
    "    else:\n",
    "        assert('Error for downloading SMS Spam Collection Dataset')\n",
    "        \n",
    "\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "if not os.path.exists(dataset_path):\n",
    "    download_dataset()\n",
    "    \n",
    "df = pd.read_csv(dataset_path, sep='\\t')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 5.4.1. Tokenization\n",
    "---\n",
    "The demo here shows how to:\n",
    "- Use regular expression for the roughly text cleanup, and\n",
    "- Use `keras.preprocessing.text.text_to_word_sequence` for sequence tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n' ...]\n",
      "['ok', 'lar', 'joking', 'wif', 'u', 'oni' ...]\n",
      "['free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa' ...]\n",
      "['u', 'dun', 'say', 'so', 'early', 'hor', 'u', 'c', 'already', 'then' ...]\n",
      "['nah', 'i', 'don', 't', 'think', 'he', 'goes', 'to', 'usf', 'he' ...]\n",
      "['freemsg', 'hey', 'there', 'darling', 'it', 's', 'been', '3', 'week', 's' ...]\n",
      "['even', 'my', 'brother', 'is', 'not', 'like', 'to', 'speak', 'with', 'me' ...]\n",
      "['as', 'per', 'your', 'request', 'melle', 'melle', 'oru', 'minnaminunginte', 'nurungu', 'vettam' ...]\n",
      "['winner', 'as', 'a', 'valued', 'network', 'customer', 'you', 'have', 'been', 'selected' ...]\n",
      "['had', 'your', 'mobile', '11', 'months', 'or', 'more', 'u', 'r', 'entitled' ...]\n",
      "['i', 'm', 'gonna', 'be', 'home', 'soon', 'and', 'i', 'don', 't' ...]\n",
      "['six', 'chances', 'to', 'win', 'cash', 'from', '100', 'to', '20', '000' ...]\n",
      "['urgent', 'you', 'have', 'won', 'a', '1', 'week', 'free', 'membership', 'in' ...]\n",
      "['i', 've', 'been', 'searching', 'for', 'the', 'right', 'words', 'to', 'thank' ...]\n",
      "['i', 'have', 'a', 'date', 'on', 'sunday', 'with', 'will' ...]\n",
      "['xxxmobilemovieclub', 'to', 'use', 'your', 'credit', 'click', 'the', 'wap', 'link', 'in' ...]\n",
      "['oh', 'k', 'i', 'm', 'watching', 'here' ...]\n",
      "['eh', 'u', 'remember', 'how', '2', 'spell', 'his', 'name', 'yes', 'i' ...]\n",
      "['fine', 'if', 'thats', 'the', 'way', 'u', 'feel', 'thats', 'the', 'way' ...]\n",
      "['england', 'v', 'macedonia', 'dont', 'miss', 'the', 'goals', 'team', 'news', 'txt' ...]\n"
     ]
    }
   ],
   "source": [
    "X_str = [ re.sub(r'(\\<[a-zA-Z\\s]+(\\/)?\\>)|[\\'\\\"\\\\]', ' ', text_raw).lower() for text_raw in df['content'] ]\n",
    "X_str = [ text_to_word_sequence(x_str) for x_str in X_str ]\n",
    "\n",
    "for i in range(0, 20):\n",
    "    print('[\\'%s\\' ...]' % '\\', \\''.join(X_str[i][0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps here encoded the string-based label into numeric-based labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'ham'), (1, 'spam')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df['label'])\n",
    "\n",
    "y = label_encoder.transform(df['label'])\n",
    "\n",
    "display( [ (idx, label) for idx, label in enumerate(label_encoder.classes_) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 5.4.2. Encode the Top-K words in Dataset\n",
    "----\n",
    "The demo here shows how to use `keras.preprocessing.text.Tokenizer` to encode each word according to word occurrences by an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t => UNK\n",
      "2\t => i\n",
      "3\t => to\n",
      "4\t => you\n",
      "5\t => a\n",
      "6\t => the\n",
      "7\t => u\n",
      "8\t => and\n",
      "9\t => in\n",
      "10\t => is\n",
      "11\t => me\n",
      "12\t => my\n",
      "13\t => it\n",
      "14\t => for\n",
      "15\t => your\n",
      "16\t => of\n",
      "17\t => call\n",
      "18\t => have\n",
      "19\t => that\n",
      "20\t => s\n",
      "21\t => on\n",
      "22\t => 2\n",
      "23\t => now\n",
      "24\t => are\n",
      "25\t => can\n",
      "26\t => so\n",
      "27\t => t\n",
      "28\t => but\n",
      "29\t => not\n",
      "30\t => m\n",
      "31\t => or\n",
      "32\t => do\n",
      "33\t => at\n",
      "34\t => we\n",
      "35\t => ur\n",
      "36\t => get\n",
      "37\t => will\n",
      "38\t => if\n",
      "39\t => be\n",
      "40\t => with\n",
      "41\t => just\n",
      "42\t => no\n",
      "43\t => this\n",
      "44\t => 4\n",
      "45\t => gt\n",
      "46\t => lt\n",
      "47\t => how\n",
      "48\t => up\n",
      "49\t => when\n",
      "50\t => ok\n"
     ]
    }
   ],
   "source": [
    "MAX_NUM_DICT_WORDS     = 2000\n",
    "MAX_SEQUENCE_LENGTH    = 50\n",
    "WORD_EMBED_DIMENSION   = 50\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='UNK', num_words=MAX_NUM_DICT_WORDS + 1)\n",
    "tokenizer.fit_on_texts(X_str)\n",
    "\n",
    "for key in sorted(tokenizer.index_word)[:50]:\n",
    "    print('%d\\t => %s' % (key, tokenizer.index_word[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the tokenized word sequences into fix-sized index-based sequences:\n",
    "- Use `Tokenizer.texts_to_sequences` for converting string list into index list, and\n",
    "- Use `keras.preprocessing.sequence.pad_sequences` for padding the sequences into fix-length index list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0   54  464    1  825  742  648   71    9 1307   94  129  336\n",
      " 1308  151    1 1309   63   62    1  141]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0   50  337 1474  465    7 1911]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0   52  482    9   22    5  783  885    3  182 1912 1086\n",
      "  649 1913    1  260    1   75 1912    3 1914    3  338  482  550  942\n",
      "   77  391   27  121   20  392    1   20]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   7 248 155  26 380   1   7 121 159  61 155]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0 1006    2   91   27  113   66\n",
      "  483    3  943   66 1915  222  118  466]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  784  135   63 1664   13   20  115  163  116   20   23    8   42  339\n",
      "   95    2  101   59  122  412    4   48   14   13   93 1916   50  364\n",
      "  942    1    3   73  323  232    3    1]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 212  12\n",
      " 621  10  29  59   3 381  40  11 106 708  11  59   1   1]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0   76  235   15 1187\n",
      " 1475 1475 1917    1    1    1  126  115  598   76   15 1007   14   55\n",
      " 1665  826  393    3 1087   15  249 1007]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0  709   76    5  827\n",
      "  437  236    4   18  115  438    3    1 1310  156  944    3  134   17\n",
      "    1  134  413    1  511  945  571   71]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0  142   15  102  675 1008   31  138\n",
      "    7   86 1188    3  484    3    6  324  528  886   40  340   14   52\n",
      "   17    6  102  484  246   52   21    1]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    2   30\n",
      "  237   39   83  223    8    2   91   27   74    3  288   85   43  289\n",
      " 1189  226  100    2  153    1  439   88]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0 1918    1    3  182  164   53\n",
      "  676    3  887  440  622   77    1    8   73    3 1919  372  192   67\n",
      "    1  253    1  392   99 1476   44  710]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0  196    4   18  154    5  123  116   52\n",
      " 1920    9   97  512  440  156    1   77    6  339  134    3   42    1\n",
      "   27  121  148    1  529    1  711    1]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    2  153\n",
      "  115 1666   14    6  158  530    3  441    4   14   43    1    2 1088\n",
      "    2  373  103   15  238   14    1    8   37    1   12 1088    4   18\n",
      "  115  712    8    5    1   33   55  496]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   2  18   5 572  21 785  40  37]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
      "    3  276   15  786 1311    6  946 1009    9    6  216   77  152   31\n",
      " 1311  118  573  946    1  193   94    1]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0 130 100   2  30 374 118]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0  888    7  394   47   22    1  213  267  143    2  114\n",
      "   66  250 1312  145  464    2  250 1667]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0  261   38 1668    6  146\n",
      "    7  217 1668    6  146   68    1  170]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0 1010  250    1   98  176\n",
      "    6    1 1313  623   77   35  551 1313    3 1190  947 1010    3 1190\n",
      "  262    1    1    1    1  887    1  253]\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(X_str)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "for i in range(0, 20):\n",
    "    print('%s' % (X[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 5.4.3. Convert each Words by External Word2Vec Data\n",
    "----\n",
    "The demo here shows how to convert the words by external **GloVe** representations.\n",
    "\n",
    "The GloVe (Global Vectors for Word Representation) is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\n",
    "\n",
    "For more information, see: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "**Notice:**\n",
    "- For this demo, you're required to manually download the `glove.6B.zip` from the project page mentioned above (822MB)\n",
    "- After downloaded, place the `glove.6B.50d.txt` under `data/demo5`\n",
    "- The word dictionary would then be built based on the tokenizer constructed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_path = os.path.join('data', 'demo5', 'glove.6B.50d.txt')\n",
    "\n",
    "if not os.path.exists(word2vec_path):\n",
    "    raise FileNotFoundError('Please follow the instructions mentioned above to get glove.6B.50d.txt')\n",
    "\n",
    "embed_mat = np.zeros( (MAX_NUM_DICT_WORDS + 1, WORD_EMBED_DIMENSION ) )\n",
    "with codecs.open(word2vec_path, 'r', 'utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        tokens = line.rstrip(' \\r\\n').split(' ')\n",
    "        \n",
    "        word_key    = tokens[0]\n",
    "        word_vector = [float(i) for i in tokens[1:]]\n",
    "        \n",
    "        if word_key in tokenizer.word_index and tokenizer.word_index[word_key] < MAX_NUM_DICT_WORDS + 1:\n",
    "            embed_mat[ tokenizer.word_index[word_key], : ] = word_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:**\n",
    "You may also discovered that some of word might not appeared in the pre-trained dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found: 1 \t[UNK]\n",
      "Not found: 192 \t[150p]\n",
      "Not found: 323 \t[£1]\n",
      "Not found: 365 \t[£1000]\n",
      "Not found: 376 \t[150ppm]\n",
      "Not found: 385 \t[aight]\n",
      "Not found: 403 \t[thanx]\n",
      "Not found: 512 \t[£100]\n",
      "Not found: 577 \t[£5000]\n",
      "Not found: 596 \t[8007]\n",
      "Not found: 603 \t[£2000]\n",
      "Not found: 614 \t[chikku]\n",
      "Not found: 617 \t[£500]\n",
      "Not found: 635 \t[86688]\n",
      "Not found: 681 \t[12hrs]\n",
      "Not found: 684 \t[msgs]\n",
      "Not found: 705 \t[knw]\n",
      "Not found: 711 \t[pobox]\n",
      "Not found: 718 \t[08000930705]\n",
      "Not found: 725 \t[ni8]\n",
      "Not found: 728 \t[frnd]\n",
      "Not found: 730 \t[boytoy]\n",
      "Not found: 735 \t[mobileupd8]\n",
      "Not found: 754 \t[mrng]\n",
      "Not found: 758 \t[oredi]\n",
      "Not found: 765 \t[suite342]\n",
      "Not found: 766 \t[2lands]\n",
      "Not found: 767 \t[08000839402]\n",
      "Not found: 772 \t[£3]\n",
      "Not found: 783 \t[wkly]\n",
      "Not found: 784 \t[freemsg]\n",
      "Not found: 791 \t[frnds]\n",
      "Not found: 811 \t[£250]\n",
      "Not found: 816 \t[savamob]\n",
      "Not found: 847 \t[87066]\n",
      "Not found: 851 \t[bslvyl]\n",
      "Not found: 855 \t[txts]\n",
      "Not found: 865 \t[£2]\n",
      "Not found: 873 \t[£350]\n",
      "Not found: 875 \t[mayb]\n",
      "Not found: 901 \t[askd]\n",
      "Not found: 907 \t[bcoz]\n",
      "Not found: 918 \t[call2optout]\n",
      "Not found: 954 \t[rply]\n",
      "Not found: 960 \t[txting]\n",
      "Not found: 980 \t[w1j6hl]\n",
      "Not found: 1007 \t[callertune]\n",
      "Not found: 1042 \t[custcare]\n",
      "Not found: 1044 \t[rakhesh]\n",
      "Not found: 1069 \t[£10]\n",
      "Not found: 1072 \t[getzed]\n",
      "Not found: 1121 \t[ldew]\n",
      "Not found: 1129 \t[£200]\n",
      "Not found: 1131 \t[11mths]\n",
      "Not found: 1134 \t[urself]\n",
      "Not found: 1146 \t[£150]\n",
      "Not found: 1147 \t[age16]\n",
      "Not found: 1162 \t[comuk]\n",
      "Not found: 1169 \t[£800]\n",
      "Not found: 1190 \t[87077]\n",
      "Not found: 1198 \t[ip4]\n",
      "Not found: 1199 \t[5we]\n",
      "Not found: 1233 \t[rcvd]\n",
      "Not found: 1241 \t[fullonsms]\n",
      "Not found: 1277 \t[polys]\n",
      "Not found: 1282 \t[08712460324]\n",
      "Not found: 1298 \t[frens]\n",
      "Not found: 1310 \t[£900]\n",
      "Not found: 1321 \t[bx420]\n",
      "Not found: 1335 \t[82277]\n",
      "Not found: 1336 \t[yijue]\n",
      "Not found: 1339 \t[62468]\n",
      "Not found: 1370 \t[08718720201]\n",
      "Not found: 1384 \t[some1]\n",
      "Not found: 1386 \t[85023]\n",
      "Not found: 1387 \t[unsub]\n",
      "Not found: 1393 \t[omw]\n",
      "Not found: 1397 \t[izzit]\n",
      "Not found: 1401 \t[shuhui]\n",
      "Not found: 1415 \t[yest]\n",
      "Not found: 1418 \t[36504]\n",
      "Not found: 1428 \t[sk38xh]\n",
      "Not found: 1440 \t[alrite]\n",
      "Not found: 1444 \t[cr9]\n",
      "Not found: 1445 \t[5wb]\n",
      "Not found: 1450 \t[lmao]\n",
      "Not found: 1458 \t[thnk]\n",
      "Not found: 1463 \t[vikky]\n",
      "Not found: 1481 \t[150pm]\n",
      "Not found: 1485 \t[don‘t]\n",
      "Not found: 1490 \t[08712300220]\n",
      "Not found: 1532 \t[aathi]\n",
      "Not found: 1534 \t[vry]\n",
      "Not found: 1539 \t[ttyl]\n",
      "Not found: 1548 \t[40gb]\n",
      "Not found: 1552 \t[l8r]\n",
      "Not found: 1554 \t[aiyo]\n",
      "Not found: 1565 \t[evng]\n",
      "Not found: 1571 \t[aftr]\n",
      "Not found: 1575 \t[txtauction]\n",
      "Not found: 1578 \t[pobox84]\n",
      "Not found: 1579 \t[w45wq]\n",
      "Not found: 1580 \t[norm150p]\n",
      "Not found: 1611 \t[sipix]\n",
      "Not found: 1612 \t[aiyah]\n",
      "Not found: 1613 \t[urawinner]\n",
      "Not found: 1614 \t[howz]\n",
      "Not found: 1616 \t[thts]\n",
      "Not found: 1622 \t[08707509020]\n",
      "Not found: 1623 \t[girlfrnd]\n",
      "Not found: 1629 \t[86021]\n",
      "Not found: 1636 \t[09050090044]\n",
      "Not found: 1637 \t[toclaim]\n",
      "Not found: 1638 \t[pobox334]\n",
      "Not found: 1640 \t[cost£1]\n",
      "Not found: 1641 \t[max10mins]\n",
      "Not found: 1646 \t[nimya]\n",
      "Not found: 1663 \t[£400]\n",
      "Not found: 1668 \t[thats]\n",
      "Not found: 1669 \t[i‘m]\n",
      "Not found: 1679 \t[urgnt]\n",
      "Not found: 1691 \t[ec2a]\n",
      "Not found: 1704 \t[2optout]\n",
      "Not found: 1715 \t[themob]\n",
      "Not found: 1725 \t[sonyericsson]\n",
      "Not found: 1726 \t[geeee]\n",
      "Not found: 1734 \t[pobox36504w45wq]\n",
      "Not found: 1743 \t[dont]\n",
      "Not found: 1753 \t[83355]\n",
      "Not found: 1758 \t[2mrw]\n",
      "Not found: 1761 \t[yogasana]\n",
      "Not found: 1762 \t[1x150p]\n",
      "Not found: 1768 \t[80062]\n",
      "Not found: 1814 \t[videochat]\n",
      "Not found: 1816 \t[dload]\n",
      "Not found: 1817 \t[noline]\n",
      "Not found: 1818 \t[rentl]\n",
      "Not found: 1826 \t[xchat]\n",
      "Not found: 1842 \t[calls£1]\n",
      "Not found: 1843 \t[80488]\n",
      "Not found: 1846 \t[pple]\n",
      "Not found: 1848 \t[linerental]\n",
      "Not found: 1855 \t[optout]\n",
      "Not found: 1878 \t[nvm]\n",
      "Not found: 1886 \t[minuts]\n",
      "Not found: 1887 \t[latr]\n",
      "Not found: 1907 \t[3510i]\n",
      "Not found: 1909 \t[mths]\n",
      "Not found: 1914 \t[87121]\n",
      "Not found: 1919 \t[87575]\n",
      "Not found: 1935 \t[becoz]\n",
      "Not found: 1938 \t[hols]\n",
      "Not found: 1950 \t[ansr]\n",
      "Not found: 1956 \t[netcollex]\n",
      "Not found: 1965 \t[4742]\n",
      "Not found: 1976 \t[recd]\n",
      "Not found: 1980 \t[com1win150ppmx3age16]\n",
      "Not found: 1981 \t[bcums]\n",
      "Not found: 1983 \t[kettoda]\n",
      "Not found: 1996 \t[belovd]\n",
      "Not found: 2000 \t[08002986906]\n"
     ]
    }
   ],
   "source": [
    "for idx, vec in enumerate(embed_mat):\n",
    "    if np.sum(vec) == 0 and idx != 0:\n",
    "        print('Not found: %d \\t[%s]' % (idx, tokenizer.index_word[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word vectors of the first 5 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i => [ 1.1891e-01  1.5255e-01 -8.2073e-02 -7.4144e-01  7.5917e-01 -4.8328e-01\n",
      " -3.1009e-01  5.1476e-01 -9.8708e-01  6.1757e-04 -1.5043e-01  8.3770e-01\n",
      " -1.0797e+00 -5.1460e-01  1.3188e+00  6.2007e-01  1.3779e-01  4.7108e-01\n",
      " -7.2874e-02 -7.2675e-01 -7.4116e-01  7.5263e-01  8.8180e-01  2.9561e-01\n",
      "  1.3548e+00 -2.5701e+00 -1.3523e+00  4.5880e-01  1.0068e+00 -1.1856e+00\n",
      "  3.4737e+00  7.7898e-01 -7.2929e-01  2.5102e-01 -2.6156e-01 -3.4684e-01\n",
      "  5.5841e-01  7.5098e-01  4.9830e-01 -2.6823e-01 -2.7443e-03 -1.8298e-02\n",
      " -2.8096e-01  5.5318e-01  3.7706e-02  1.8555e-01 -1.5025e-01 -5.7512e-01\n",
      " -2.6671e-01  9.2121e-01]\n",
      "\n",
      "to => [ 0.68047  -0.039263  0.30186  -0.17792   0.42962   0.032246 -0.41376\n",
      "  0.13228  -0.29847  -0.085253  0.17118   0.22419  -0.10046  -0.43653\n",
      "  0.33418   0.67846   0.057204 -0.34448  -0.42785  -0.43275   0.55963\n",
      "  0.10032   0.18677  -0.26854   0.037334 -2.0932    0.22171  -0.39868\n",
      "  0.20912  -0.55725   3.8826    0.47466  -0.95658  -0.37788   0.20869\n",
      " -0.32752   0.12751   0.088359  0.16351  -0.21634  -0.094375  0.018324\n",
      "  0.21048  -0.03088  -0.19722   0.082279 -0.09434  -0.073297 -0.064699\n",
      " -0.26044 ]\n",
      "\n",
      "you => [-1.0919e-03  3.3324e-01  3.5743e-01 -5.4041e-01  8.2032e-01 -4.9391e-01\n",
      " -3.2588e-01  1.9972e-03 -2.3829e-01  3.5554e-01 -6.0655e-01  9.8932e-01\n",
      " -2.1786e-01  1.1236e-01  1.1494e+00  7.3284e-01  5.1182e-01  2.9287e-01\n",
      "  2.8388e-01 -1.3590e+00 -3.7951e-01  5.0943e-01  7.0710e-01  6.2941e-01\n",
      "  1.0534e+00 -2.1756e+00 -1.3204e+00  4.0001e-01  1.5741e+00 -1.6600e+00\n",
      "  3.7721e+00  8.6949e-01 -8.0439e-01  1.8390e-01 -3.4332e-01  1.0714e-02\n",
      "  2.3969e-01  6.6748e-02  7.0117e-01 -7.3702e-01  2.0877e-01  1.1564e-01\n",
      " -1.5190e-01  8.5908e-01  2.2620e-01  1.6519e-01  3.6309e-01 -4.5697e-01\n",
      " -4.8969e-02  1.1316e+00]\n",
      "\n",
      "a => [ 0.21705   0.46515  -0.46757   0.10082   1.0135    0.74845  -0.53104\n",
      " -0.26256   0.16812   0.13182  -0.24909  -0.44185  -0.21739   0.51004\n",
      "  0.13448  -0.43141  -0.03123   0.20674  -0.78138  -0.20148  -0.097401\n",
      "  0.16088  -0.61836  -0.18504  -0.12461  -2.2526   -0.22321   0.5043\n",
      "  0.32257   0.15313   3.9636   -0.71365  -0.67012   0.28388   0.21738\n",
      "  0.14433   0.25926   0.23434   0.4274   -0.44451   0.13813   0.36973\n",
      " -0.64289   0.024142 -0.039315 -0.26037   0.12017  -0.043782  0.41013\n",
      "  0.1796  ]\n",
      "\n",
      "the => [ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
      " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
      " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
      " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
      " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
      "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
      "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
      " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
      " -1.1514e-01 -7.8581e-01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,7):\n",
    "    print('%s => %s\\n' % (tokenizer.index_word[i], embed_mat[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 5.4.4. Learning with LSTM\n",
    "----\n",
    "The demo here shows how to train a LSTM model based on pre-processed text-sequences, then conduct the classification problem for recognizing spam and legitimate messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(MAX_NUM_DICT_WORDS + 1, WORD_EMBED_DIMENSION, weights=[embed_mat], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 50)            100050    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 146,387\n",
      "Trainable params: 46,337\n",
      "Non-trainable params: 100,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 2s 436us/step - loss: 0.2631 - acc: 0.8977\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 1s 284us/step - loss: 0.0950 - acc: 0.9686\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 1s 310us/step - loss: 0.0728 - acc: 0.9771\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 1s 271us/step - loss: 0.0661 - acc: 0.9787\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 1s 252us/step - loss: 0.0604 - acc: 0.9805\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 1s 242us/step - loss: 0.0546 - acc: 0.9829\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 1s 236us/step - loss: 0.0474 - acc: 0.9859\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 1s 235us/step - loss: 0.0393 - acc: 0.9877\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 1s 237us/step - loss: 0.0389 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 1s 231us/step - loss: 0.0332 - acc: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15199d5c390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_lstm()\n",
    "model.summary()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate = 0.013\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "idx_true = y_test_predict > 0.9\n",
    "y_test_predict [ idx_true ] = 1\n",
    "y_test_predict [ ~idx_true ] = 0\n",
    "y_test_predict = y_test_predict.astype(int)\n",
    "\n",
    "# Error rate\n",
    "err_01loss = zero_one_loss(y_test, y_test_predict)\n",
    "print('Error rate = %2.3f' % err_01loss)\n",
    "\n",
    "# Confusion matrix of prediction\n",
    "plot_conf_mat = PlotMetric(figsize=(4, 4))\n",
    "plot_conf_mat.set_labels(label_encoder.classes_.tolist())\n",
    "plot_conf_mat.confusion_matrix(y_test, y_test_predict, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
